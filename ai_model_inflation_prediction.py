import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Load preprocessed data
DATA_PATH = "data/merged_data.csv"  # Ensure this file is generated by the data pipeline
data = pd.read_csv(DATA_PATH)

# Check the data structure
print("Data Head:")
print(data.head())

# Select relevant features for prediction
features = ['gold_price', 'stock_index', 'inflation_rate']
data = data[features]

# Fill missing values (if any)
data.fillna(method='ffill', inplace=True)

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Prepare the dataset for LSTM
def create_sequences(data, sequence_length):
    sequences = []
    targets = []
    for i in range(sequence_length, len(data)):
        sequences.append(data[i-sequence_length:i, :])
        targets.append(data[i, 2])  # Inflation rate as the target
    return np.array(sequences), np.array(targets)

# Hyperparameters
SEQUENCE_LENGTH = 60  # Use 60 days of historical data to predict the next day's inflation rate
TRAIN_SPLIT = 0.8  # 80% of the data for training, 20% for testing

# Split the data
train_size = int(len(scaled_data) * TRAIN_SPLIT)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

x_train, y_train = create_sequences(train_data, SEQUENCE_LENGTH)
x_test, y_test = create_sequences(test_data, SEQUENCE_LENGTH)

# Build the LSTM model
model = Sequential([
    LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])),
    Dropout(0.2),
    LSTM(64, return_sequences=False),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1)  # Single output for inflation rate
])

model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Train the model
history = model.fit(
    x_train, y_train,
    validation_data=(x_test, y_test),
    epochs=20,
    batch_size=32,
    verbose=1
)

# Evaluate the model
loss, mae = model.evaluate(x_test, y_test)
print(f"Test Loss: {loss}, Test MAE: {mae}")

# Plot training history
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Training History')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(
    np.concatenate((np.zeros((predictions.shape[0], 2)), predictions), axis=1)
)[:, 2]

# Compare predictions with actual values
actual_values = scaler.inverse_transform(
    np.concatenate((np.zeros((y_test.shape[0], 2)), y_test.reshape(-1, 1)), axis=1)
)[:, 2]

plt.figure(figsize=(10, 6))
plt.plot(actual_values, label='Actual Inflation Rates')
plt.plot(predictions, label='Predicted Inflation Rates')
plt.title('Inflation Rate Predictions vs Actual')
plt.xlabel('Time')
plt.ylabel('Inflation Rate')
plt.legend()
plt.show()

# Save the model
MODEL_PATH = "models/inflation_prediction_model.h5"
model.save(MODEL_PATH)
print(f"Model saved to {MODEL_PATH}")